import os
import json
import subprocess
import logging
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import whisper
import openai
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip
import yt_dlp
import shutil
import re
from dotenv import load_dotenv

def sanitize_filename(filename: str) -> str:
    """
    Nettoie un nom de fichier pour le rendre compatible avec le syst√®me de fichiers.
    
    Args:
        filename (str): Nom de fichier √† nettoyer
        
    Returns:
        str: Nom de fichier nettoy√©
    """
    # Remplace les caract√®res non autoris√©s par des underscores
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    # Limite la longueur du nom de fichier
    return filename[:255]

class VideoProcessor:
    def __init__(self, config: Dict):
        """
        Initialise le processeur vid√©o avec la configuration sp√©cifi√©e.
        
        Args:
            config (Dict): Configuration du processeur
        """
        self.config = config
        self.setup_logging()
        self._init_models()
        
        # Chemins de sortie
        self.output_dir = config.get('paths', {}).get('outputs', 'outputs')
        self.temp_dir = config.get('paths', {}).get('temp', 'temp')
        self.downloads_dir = config.get('paths', {}).get('downloads', 'downloads')
        
        # Cr√©ation des r√©pertoires n√©cessaires
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.temp_dir, exist_ok=True)
        os.makedirs(self.downloads_dir, exist_ok=True)
        
    def sanitize_filename(self, filename: str) -> str:
        """
        Nettoie un nom de fichier pour le rendre compatible avec le syst√®me de fichiers.
        
        Args:
            filename (str): Nom de fichier √† nettoyer
            
        Returns:
            str: Nom de fichier nettoy√©
        """
        # Remplace les caract√®res non autoris√©s par des underscores
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # Limite la longueur du nom de fichier
        return filename[:255]
        
    def setup_logging(self):
        """Configure le syst√®me de logging."""
        self.logger = logging.getLogger('VideoProcessor')
        self.logger.setLevel(logging.INFO)
        
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            
    def _init_models(self):
        """Initialise les mod√®les Whisper et OpenAI."""
        try:
            # Initialisation de Whisper avec le mod√®le medium
            self.logger.info("üîÑ Chargement du mod√®le Whisper medium...")
            self.whisper_model = whisper.load_model("medium")
            self.logger.info("‚úÖ Mod√®le Whisper charg√© avec succ√®s")
            
            # Initialisation du client OpenAI si une cl√© API est fournie
            api_key = self.config.get('api', {}).get('openai', {}).get('api_key')
            
            # Si la cl√© n'est pas dans la config, essayer de la r√©cup√©rer depuis les variables d'environnement
            if not api_key:
                load_dotenv()
                api_key = os.getenv('OPENAI_API_KEY')
            
            if api_key:
                openai.api_key = api_key
                self.logger.info("‚úÖ Client OpenAI initialis√©")
            else:
                self.logger.warning("‚ö†Ô∏è Pas de cl√© API OpenAI fournie, la correction GPT sera d√©sactiv√©e")
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de l'initialisation des mod√®les: {str(e)}")
            raise
            
    def process_video(self, video_path: str, dry_run: bool = False, video_metadata: Dict = None) -> List[str]:
        """
        Traite une vid√©o en la d√©coupant en segments et en ajoutant des sous-titres.
        
        Args:
            video_path (str): Chemin de la vid√©o √† traiter
            dry_run (bool): Si True, ne fait que l'analyse sans export
            video_metadata (Dict): M√©tadonn√©es de la vid√©o YouTube
            
        Returns:
            List[str]: Liste des chemins des vid√©os trait√©es
        """
        try:
            self.logger.info(f"üé• Traitement de la vid√©o: {video_path}")
            
            # D√©coupage de la vid√©o
            segments = self._split_video(video_path)
            self.logger.info(f"‚úÇÔ∏è Vid√©o d√©coup√©e en {len(segments)} segments")
            
            processed_videos = []
            for i, segment in enumerate(segments):
                self.logger.info(f"üîÑ Traitement du segment {i+1}/{len(segments)}")
                
                # G√©n√©ration des sous-titres
                subtitles = self._generate_subtitles_for_segment(segment)
                
                # Sauvegarde des sous-titres
                srt_path = os.path.join(self.temp_dir, f"segment_{i+1}.srt")
                self._save_srt(subtitles, srt_path)
                
                # Ajout des sous-titres √† la vid√©o
                output_path = os.path.join(self.output_dir, f"segment_{i+1}_with_subs.mp4")
                if not dry_run:
                    if self._add_subtitles_ffmpeg(segment, srt_path, output_path):
                        processed_videos.append(output_path)
                        self.logger.info(f"‚úÖ Segment {i+1} trait√© avec succ√®s")
                        
                        # G√©n√©ration et sauvegarde des m√©tadonn√©es
                        transcript = ' '.join([s['text'] for s in subtitles]) if subtitles else ''
                        metadata = self._generate_metadata(i+1, video_metadata, transcript)
                        self._save_metadata(metadata, output_path)
                    else:
                        self.logger.error(f"‚ùå Erreur lors du traitement du segment {i+1}")
                else:
                    self.logger.info(f"üîç Mode analyse: segment {i+1} analys√©")
                    
            return processed_videos
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors du traitement de la vid√©o: {str(e)}")
            return []
            
    def _split_video(self, video_path: str) -> List[str]:
        """
        D√©coupe une vid√©o en segments de dur√©e √©gale.
        
        Args:
            video_path (str): Chemin de la vid√©o √† d√©couper
            
        Returns:
            List[str]: Liste des chemins des segments
        """
        try:
            # Chargement de la vid√©o
            video = VideoFileClip(video_path)
            duration = video.duration
            
            # Calcul de la dur√©e des segments (60 secondes par d√©faut)
            segment_duration = self.config.get('segment_duration', 60)
            num_segments = int(duration / segment_duration) + (1 if duration % segment_duration > 0 else 0)
            
            segments = []
            for i in range(num_segments):
                start_time = i * segment_duration
                end_time = min((i + 1) * segment_duration, duration)
                
                # Extraction du segment
                segment = video.subclip(start_time, end_time)
                
                # Sauvegarde du segment
                segment_path = os.path.join(self.temp_dir, f"segment_{i+1}.mp4")
                segment.write_videofile(segment_path, codec='libx264', audio_codec='aac')
                segments.append(segment_path)
                
            video.close()
            return segments
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors du d√©coupage de la vid√©o: {str(e)}")
            return []
            
    def _generate_subtitles_for_segment(self, video_path: str) -> List[Dict]:
        """
        G√©n√®re les sous-titres pour un segment vid√©o en utilisant Whisper.
        
        Args:
            video_path (str): Chemin du segment vid√©o
            
        Returns:
            List[Dict]: Liste des segments de sous-titres
        """
        try:
            # Transcription avec Whisper
            self.logger.info("üéØ Transcription du segment...")
            result = self.whisper_model.transcribe(video_path)
            
            # Nettoyage et optimisation des segments
            segments = self.clean_segments(result['segments'])
            
            # Correction avec GPT si disponible
            if hasattr(self, 'openai_api_key'):
                segments = self.post_correct_transcription(segments)
                
            return segments
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la g√©n√©ration des sous-titres: {str(e)}")
            return []
            
    def clean_segments(self, segments: List[Dict]) -> List[Dict]:
        """
        Nettoie et optimise les segments de sous-titres.
        
        Args:
            segments (List[Dict]): Liste des segments √† nettoyer
            
        Returns:
            List[Dict]: Liste des segments nettoy√©s
        """
        cleaned_segments = []
        current_segment = None
        
        for segment in segments:
            # Fusion des segments courts (< 1.2s)
            if segment['end'] - segment['start'] < 1.2:
                if current_segment is None:
                    current_segment = segment.copy()
                else:
                    current_segment['end'] = segment['end']
                    current_segment['text'] += ' ' + segment['text']
                continue
                
            # D√©coupage des segments longs (> 6s)
            if segment['end'] - segment['start'] > 6:
                duration = segment['end'] - segment['start']
                num_parts = int(duration / 6) + 1
                part_duration = duration / num_parts
                
                for i in range(num_parts):
                    start = segment['start'] + i * part_duration
                    end = start + part_duration
                    text = segment['text']  # Le texte sera r√©parti √©quitablement
                    
                    cleaned_segments.append({
                        'start': start,
                        'end': end,
                        'text': text
                    })
            else:
                cleaned_segments.append(segment)
                
        # Ajout du dernier segment en cours si n√©cessaire
        if current_segment is not None:
            cleaned_segments.append(current_segment)
            
        return cleaned_segments
        
    def post_correct_transcription(self, segments: List[Dict]) -> List[Dict]:
        """
        Corrige la transcription avec GPT pour am√©liorer la qualit√©.
        
        Args:
            segments (List[Dict]): Liste des segments √† corriger
            
        Returns:
            List[Dict]: Liste des segments corrig√©s
        """
        try:
            # Pr√©paration du texte pour GPT
            text = ' '.join(segment['text'] for segment in segments)
            
            # Appel √† l'API OpenAI
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Tu es un expert en correction de transcription. Corrige les erreurs de ponctuation et de majuscules tout en pr√©servant le style oral."},
                    {"role": "user", "content": text}
                ]
            )
            
            # R√©cup√©ration du texte corrig√©
            corrected_text = response.choices[0].message.content
            
            # R√©partition du texte corrig√© sur les segments
            words = corrected_text.split()
            words_per_segment = len(words) // len(segments)
            
            for i, segment in enumerate(segments):
                start_idx = i * words_per_segment
                end_idx = start_idx + words_per_segment if i < len(segments) - 1 else len(words)
                segment['text'] = ' '.join(words[start_idx:end_idx])
                
            return segments
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la correction GPT: {str(e)}")
            return segments
            
    def _save_srt(self, segments: List[Dict], output_path: str):
        """
        Sauvegarde les sous-titres au format SRT.
        
        Args:
            segments (List[Dict]): Liste des segments de sous-titres
            output_path (str): Chemin de sortie du fichier SRT
        """
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                for i, segment in enumerate(segments, 1):
                    # Conversion des timestamps
                    start = self._format_timestamp(segment['start'])
                    end = self._format_timestamp(segment['end'])
                    
                    # √âcriture du segment
                    f.write(f"{i}\n")
                    f.write(f"{start} --> {end}\n")
                    f.write(f"{segment['text']}\n\n")
                    
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la sauvegarde des sous-titres: {str(e)}")
            
    def _format_timestamp(self, seconds: float) -> str:
        """
        Convertit des secondes en timestamp SRT.
        
        Args:
            seconds (float): Nombre de secondes
            
        Returns:
            str: Timestamp au format SRT (HH:MM:SS,mmm)
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = seconds % 60
        milliseconds = int((seconds - int(seconds)) * 1000)
        return f"{hours:02d}:{minutes:02d}:{int(seconds):02d},{milliseconds:03d}"
        
    def _add_subtitles_ffmpeg(self, video_path: str, srt_path: str, output_path: str) -> bool:
        """
        Ajoute des sous-titres √† une vid√©o avec FFmpeg en utilisant un style fixe TikTok-friendly.
        
        Args:
            video_path (str): Chemin de la vid√©o d'entr√©e
            srt_path (str): Chemin du fichier SRT
            output_path (str): Chemin de la vid√©o de sortie
            
        Returns:
            bool: True si l'ajout des sous-titres a r√©ussi, False sinon
        """
        try:
            # V√©rification des fichiers
            if not os.path.exists(video_path):
                self.logger.error(f"‚ùå Vid√©o introuvable: {video_path}")
                return False
            if not os.path.exists(srt_path):
                self.logger.error(f"‚ùå Fichier SRT introuvable: {srt_path}")
                return False
                
            # V√©rification de FFmpeg
            try:
                subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
                self.logger.info("‚úÖ FFmpeg est disponible")
            except (subprocess.SubprocessError, FileNotFoundError):
                self.logger.error("‚ùå FFmpeg n'est pas install√© ou n'est pas accessible")
                return False
                
            # R√©cup√©ration des dimensions de la vid√©o
            probe_cmd = [
                'ffprobe',
                '-v', 'error',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=width,height',
                '-of', 'json',
                video_path
            ]
            result = subprocess.run(probe_cmd, capture_output=True, text=True)
            if result.returncode != 0:
                self.logger.error("‚ùå Erreur lors de l'analyse de la vid√©o")
                return False
                
            # Calcul de la taille de police adaptative
            video_info = json.loads(result.stdout)
            width = video_info['streams'][0]['width']
            height = video_info['streams'][0]['height']
            min_dim = min(width, height)
            font_size = max(24, min(30, int(min_dim * 0.04)))  # Police plus petite et adaptative
            
            # Utilisation de drawtext pour plus de contr√¥le
            drawtext_filter = self._convert_srt_to_drawtext(srt_path, width, height, font_size)
            
            # Commande FFmpeg avec drawtext
            cmd = [
                'ffmpeg',
                '-y',
                '-i', video_path,
                '-vf', drawtext_filter,
                '-c:v', 'libx264',
                '-preset', 'medium',
                '-crf', '23',
                '-c:a', 'copy',
                output_path
            ]
            
            # Ex√©cution de la commande
            self.logger.info(f"üîÑ Ajout des sous-titres...")
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                self.logger.error(f"‚ùå Erreur lors de l'ajout des sous-titres: {result.stderr}")
                return False
                    
            # V√©rification que la vid√©o de sortie existe et contient des sous-titres
            if os.path.exists(output_path):
                # V√©rification rapide avec ffprobe
                probe_cmd = [
                    'ffprobe',
                    '-v', 'error',
                    '-select_streams', 'v:0',
                    '-show_entries', 'stream=codec_name',
                    '-of', 'json',
                    output_path
                ]
                result = subprocess.run(probe_cmd, capture_output=True, text=True)
                if result.returncode == 0:
                    self.logger.info("‚úÖ Sous-titres ajout√©s avec succ√®s")
                    return True
                else:
                    self.logger.error("‚ùå La vid√©o de sortie n'a pas √©t√© correctement g√©n√©r√©e")
                    return False
            else:
                self.logger.error("‚ùå La vid√©o de sortie n'a pas √©t√© g√©n√©r√©e")
                return False
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de l'ajout des sous-titres: {str(e)}")
            return False
            
    def _convert_srt_to_drawtext(self, srt_path: str, width: int, height: int, font_size: int) -> str:
        """
        Convertit un fichier SRT en filtre drawtext FFmpeg avec style discret et lisible (TikTok-friendly).
        
        Args:
            srt_path (str): Chemin du fichier SRT
            width (int): Largeur de la vid√©o
            height (int): Hauteur de la vid√©o
            font_size (int): Taille de la police
        
        Returns:
            str: Filtre drawtext FFmpeg
        """
        try:
            drawtext_parts = []

            # Adapter la taille pour rester sobre et lisible
            font_size = max(24, min(30, int(min(width, height) * 0.04)))

            with open(srt_path, 'r', encoding='utf-8') as f:
                content = f.read()
                segments = content.strip().split('\n\n')

                for segment in segments:
                    lines = segment.strip().split('\n')
                    if len(lines) >= 3:
                        timing = lines[1]
                        text = lines[2].strip()

                        # √âchapper les caract√®res sp√©ciaux pour FFmpeg
                        text = text.replace("'", "'\\\\\\''")  # Triple escape pour FFmpeg
                        text = text.replace(":", "\\:")
                        text = text.replace("[", "\\[")
                        text = text.replace("]", "\\]")
                        text = text.replace(",", "\\,")
                        text = text.replace("(", "\\(")
                        text = text.replace(")", "\\)")

                        # Split en 2 lignes max si n√©cessaire
                        if len(text) > 50:
                            midpoint = len(text) // 2
                            space_index = text.find(' ', midpoint)
                            if space_index != -1:
                                text = text[:space_index] + '\\n' + text[space_index+1:]

                        # Conversion du timing
                        try:
                            start_time, end_time = timing.split(' --> ')
                            start_seconds = self._srt_time_to_seconds(start_time)
                            end_seconds = self._srt_time_to_seconds(end_time)

                            # Filtre les sous-titres avec un end mal format√© ou une dur√©e excessive (bug d'encodage possible)
                            max_duration = 15  # 15s max pour un seul sous-titre
                            duration = end_seconds - start_seconds

                            if (
                                0 <= start_seconds < end_seconds
                                and 0 < duration <= max_duration
                                and text.strip()
                            ):
                                # Style drawtext simple et propre
                                drawtext = (
                                    f"drawtext=text='{text}':"
                                    f"fontfile=/System/Library/Fonts/Supplemental/Arial Bold.ttf:"
                                    f"fontsize={font_size}:"
                                    f"fontcolor=white:"
                                    f"box=1:"
                                    f"boxcolor=black@0.7:"
                                    f"boxborderw=5:"
                                    f"line_spacing=4:"
                                    f"x=(w-text_w)/2:"
                                    f"y=h-text_h-40:"
                                    f"enable='between(t,{start_seconds:.3f},{end_seconds:.3f})'"
                                )
                                drawtext_parts.append(drawtext)
                                self.logger.debug(f"Filtre drawtext g√©n√©r√©: {drawtext}")
                            else:
                                self.logger.warning(
                                    f"‚è±Ô∏è Segment ignor√© (dur√©e invalide ou trop longue) : start={start_seconds}, end={end_seconds}, text='{text[:30]}'"
                                )
                        except Exception as e:
                            self.logger.warning(f"‚ö†Ô∏è Erreur lors du traitement du segment: {str(e)}")
                            continue

            if not drawtext_parts:
                self.logger.warning("‚ö†Ô∏è Aucun filtre drawtext g√©n√©r√©")
                return ""

            final_filter = ','.join(drawtext_parts)
            self.logger.debug(f"Filtre drawtext final: {final_filter}")
            return final_filter

        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la conversion SRT vers drawtext: {str(e)}")
            return ""
            
    def _srt_time_to_seconds(self, time_str: str) -> float:
        """
        Convertit un timestamp SRT en secondes.
        
        Args:
            time_str (str): Timestamp au format SRT (HH:MM:SS,mmm)
            
        Returns:
            float: Nombre de secondes
        """
        try:
            # Format: HH:MM:SS,mmm
            hours, minutes, seconds = time_str.replace(',', '.').split(':')
            total_seconds = (
                int(hours) * 3600 +
                int(minutes) * 60 +
                float(seconds)
            )
            # Arrondir √† 3 d√©cimales et s'assurer que la valeur est positive
            total_seconds = max(0, round(total_seconds, 3))
            return total_seconds
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la conversion du timestamp {time_str}: {str(e)}")
            return 0.0
        
    def _cleanup_temp_files(self, file_paths: List[str]):
        """
        Nettoie les fichiers temporaires.
        
        Args:
            file_paths (List[str]): Liste des chemins de fichiers √† supprimer
        """
        for path in file_paths:
            try:
                if os.path.exists(path):
                    os.remove(path)
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Impossible de supprimer le fichier temporaire {path}: {str(e)}")

    def _generate_metadata(self, segment_number: int, video_metadata: Dict, transcript: str) -> Dict:
        """
        G√©n√®re les m√©tadonn√©es pour un segment vid√©o.
        
        Args:
            segment_number (int): Num√©ro du segment
            video_metadata (Dict): M√©tadonn√©es de la vid√©o YouTube
            transcript (str): Transcription du segment
            
        Returns:
            Dict: M√©tadonn√©es g√©n√©r√©es
        """
        try:
            if not video_metadata:
                return {
                    'title': f'Segment {segment_number}',
                    'description': 'Segment vid√©o automatiquement g√©n√©r√©',
                    'hashtags': ['#tiktok', '#viral', '#trending']
                }

            # V√©rification de la cl√© API OpenAI
            openai_api_key = self.config.get('api', {}).get('openai', {}).get('api_key')
            if not openai_api_key:
                self.logger.warning("‚ö†Ô∏è Aucune cl√© API OpenAI trouv√©e, utilisation du mode basique")
                return {
                    'title': f"{video_metadata.get('title', 'Vid√©o')} (partie {segment_number})",
                    'description': f"‚ú® D√©couvre la suite de cette vid√©o incroyable ! üí´ Like et commente si tu veux voir la suite üëá",
                    'hashtags': ['#tiktok', '#viral', '#trending', '#fyp', '#pourtoi', '#foryoupage', '#decouverte']
                }

            # Utilisation de l'API OpenAI pour g√©n√©rer des m√©tadonn√©es pertinentes
            prompt = f"""
            Tu es un expert en cr√©ation de contenu viral pour TikTok.

            Ta mission est de g√©n√©rer des **m√©tadonn√©es engageantes et distinctes** pour un segment vid√©o court √† partir des informations suivantes :

            üé¨ CONTEXTE ORIGINAL :
            - Titre YouTube : {video_metadata.get('title', 'Non disponible')}
            - Description YouTube : {video_metadata.get('description', 'Non disponible')}
            - Cha√Æne : {video_metadata.get('channel_title', 'Non disponible')}
            - Vues : {video_metadata.get('views', 0):,}
            - Date de publication : {video_metadata.get('published_at', 'Non disponible')}

            üìù TRANSCRIPTION DU SEGMENT ({segment_number}) :
            {transcript[:1000]}

            üéØ OBJECTIF :
            Cr√©er un **titre, une description et des hashtags TikTok uniques** pour ce **segment** en particulier. Le style doit rester **naturel, humain, percutant et TikTok-friendly**, et s'adapter au **contenu r√©el du segment**, qu'il soit informatif, divertissant, √©motionnel ou autre.

            ‚öôÔ∏è DIRECTIVES :

            1. **TITRE (max. 100 caract√®res)** :
               - Accroche fort : √©motion, choc, r√©v√©lation, humour, etc.
               - Mentionne "(partie {segment_number})" √† la fin
               - Ne jamais copier le titre YouTube
               - √âvite les titres g√©n√©riques
               - Utilise au plus 1 ou 2 emojis bien plac√©s

            2. **DESCRIPTION (max. 150 caract√®res)** :
               - Diff√©rente du titre
               - Naturelle et engageante
               - Peut poser une question, teaser un moment ou ajouter du contexte
               - 1 √† 3 emojis max, pas plus
               - Appelle √† interagir : commentaires, opinions, r√©actions

            3. **HASHTAGS (entre 5 et 7)** :
               - M√©lange entre hashtags populaires TikTok (FR ou global) et hashtags de niche
               - Inclure des hashtags en lien avec le contenu r√©el (ex: #histoire, #funny, #cinema, #rapfr, etc.)
               - √âvite de toujours r√©p√©ter les m√™mes (#tiktok, #foryou, etc.)
               - Minimum 3 hashtags diff√©rents d'un segment √† l'autre

            üì¶ FORMAT DE SORTIE ATTENDU (JSON strict) :
            {{
              "title": "Titre TikTok",
              "description": "Description TikTok",
              "hashtags": ["#hashtag1", "#hashtag2", "#hashtag3", "#hashtag4", "#hashtag5"]
            }}

            ‚ö†Ô∏è CONTRAINTES :
            - Pas de titre ou description identique entre segments
            - Pas de surcharge d'emojis
            - Aucune r√©p√©tition inutile
            - Si le contenu ne permet pas une accroche forte, adopte un ton sobre et authentique
            """
            
            try:
                client = openai.OpenAI(api_key=openai_api_key)
                response = client.chat.completions.create(
                    model=self.config['api']['openai'].get('model', 'gpt-3.5-turbo'),
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7
                )
                
                metadata = json.loads(response.choices[0].message.content)
                
                # V√©rification et nettoyage des m√©tadonn√©es
                metadata['title'] = metadata['title'].strip()
                if len(metadata['title']) > 100:
                    metadata['title'] = metadata['title'][:97] + "..."
                
                metadata['description'] = metadata['description'].strip()
                if len(metadata['description']) > 150:
                    metadata['description'] = metadata['description'][:147] + "..."
                
                # Limitation du nombre de hashtags
                metadata['hashtags'] = metadata['hashtags'][:7]
                
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Erreur lors de la g√©n√©ration GPT des m√©tadonn√©es: {str(e)}")
                # Fallback en mode basique avec des hashtags vari√©s
                metadata = {
                    'title': f"{video_metadata.get('title', 'Vid√©o')} (partie {segment_number})",
                    'description': f"‚ú® D√©couvre la suite de cette vid√©o incroyable ! üí´ Like et commente si tu veux voir la suite üëá",
                    'hashtags': ['#tiktok', '#viral', '#trending', '#fyp', '#pourtoi', '#foryoupage', '#decouverte']
                }
                
            # Ajout des m√©tadonn√©es suppl√©mentaires
            metadata['generated_date'] = datetime.now().isoformat()
            metadata['original_video_id'] = video_metadata.get('video_id', '')
            metadata['segment_number'] = segment_number
            metadata['channel_title'] = video_metadata.get('channel_title', '')
            metadata['views'] = video_metadata.get('views', 0)
            metadata['published_at'] = video_metadata.get('published_at', '')
            
            return metadata
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la g√©n√©ration des m√©tadonn√©es: {str(e)}")
            return {
                'title': f'Segment {segment_number}',
                'description': 'Segment vid√©o automatiquement g√©n√©r√©',
                'hashtags': ['#tiktok', '#viral', '#trending', '#fyp', '#pourtoi', '#foryoupage', '#decouverte']
            }

    def _save_metadata(self, metadata: Dict, output_path: str):
        """
        Sauvegarde les m√©tadonn√©es dans un fichier texte.
        
        Args:
            metadata (Dict): M√©tadonn√©es √† sauvegarder
            output_path (str): Chemin du fichier vid√©o associ√©
        """
        try:
            metadata_path = os.path.splitext(output_path)[0] + '.txt'
            with open(metadata_path, 'w', encoding='utf-8') as f:
                f.write(f"Titre: {metadata.get('title', '')}\n")
                f.write(f"Description: {metadata.get('description', '')}\n")
                f.write(f"Hashtags: {' '.join(metadata.get('hashtags', []))}\n")
                f.write(f"Date de g√©n√©ration: {metadata.get('generated_date', '')}\n")
                f.write(f"ID vid√©o originale: {metadata.get('original_video_id', '')}\n")
                f.write(f"Num√©ro de segment: {metadata.get('segment_number', '')}\n")
                
            self.logger.info(f"‚úÖ M√©tadonn√©es sauvegard√©es dans {metadata_path}")
            
            # Renommer le fichier MP4 avec le titre g√©n√©r√©
            self._rename_video_with_metadata(output_path, metadata_path)
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la sauvegarde des m√©tadonn√©es: {str(e)}")

    def _rename_video_with_metadata(self, video_path: str, metadata_path: str):
        """
        Renomme le fichier vid√©o en utilisant le titre des m√©tadonn√©es.
        
        Args:
            video_path (str): Chemin du fichier vid√©o
            metadata_path (str): Chemin du fichier de m√©tadonn√©es
        """
        try:
            # Lire le titre depuis le fichier de m√©tadonn√©es
            with open(metadata_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.startswith('Titre:'):
                        title = line.replace('Titre:', '').strip()
                        break
            
            if title:
                # Nettoyer le titre pour le nom de fichier
                safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_', '|', '(', ')')).strip()
                new_video_path = os.path.join(os.path.dirname(video_path), f"{safe_title}.mp4")
                
                # Renommer le fichier
                os.rename(video_path, new_video_path)
                self.logger.info(f"‚úÖ Fichier vid√©o renomm√©: {new_video_path}")
                
                # Mettre √† jour le chemin des m√©tadonn√©es
                new_metadata_path = os.path.splitext(new_video_path)[0] + '.txt'
                os.rename(metadata_path, new_metadata_path)
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors du renommage du fichier: {str(e)}")

    def organize_outputs(self, output_paths: List[str], video_title: str) -> None:
        """Organise les fichiers de sortie dans une structure de dossiers."""
        try:
            # Cr√©er le dossier principal pour la vid√©o
            safe_title = self.sanitize_filename(video_title)
            base_dir = os.path.join(self.config['paths']['outputs'], safe_title)
            os.makedirs(base_dir, exist_ok=True)
            
            # D√©placer les fichiers dans le dossier principal
            for path in output_paths:
                if path and os.path.exists(path):
                    # D√©placer le fichier
                    filename = os.path.basename(path)
                    new_path = os.path.join(base_dir, filename)
                    shutil.move(path, new_path)
                    self.logger.info(f"Fichier d√©plac√© vers {new_path}")
            
            self.logger.info(f"Organisation des fichiers termin√©e dans {base_dir}")
            
        except Exception as e:
            self.logger.error(f"Erreur lors de l'organisation des fichiers: {str(e)}")
            raise 